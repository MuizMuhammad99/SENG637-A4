**SENG 637 - Dependability and Reliability of Software Systems**

**Lab. Report \#4 â€“ Mutation Testing and Web app testing**

| Group \#:      |     |
| -------------- | --- |
| Student Names: |     |
|                |     |
|                |     |
|                |     |

# Introduction

# Analysis of 10 Mutants of the Range class 
- To examine 10 mutants generated by executing Pitest on the Range class, let us consider five distinct methods within the Range class. Within each method, we select two mutants and analyze how they were killed or not by the original test suite.
    * Method 01: getLowerBound():
        * Generated Mutant 01: Negated double field lower 
            * Mutation Status: Killed
            * Analysis of the mutant: This mutant negates the value of the 'lower' field in the Range class. That is, if a positive lower bound value is expected, this mutant would return a negative value instead.
            * Original test suite test case that likely killed this mutant: getLowerBoundWithNegativeRange()
        * Generated Mutant 02: replaced double return with 0.0d for org/jfree/data/Range::getLowerBound
            * Mutation Status: Killed
            * Analysis of the mutant: This mutant indicates that the method will always return 0.0, irrespective of what the actual lower bound of the range is. 
            * Original test suite test case that likely killed this mutant: getLowerBoundWithNegativeRange() since it expects a distinctly non-zero, negative value, making it impossible for the mutant to pass this test. 
    * Method 02: getCentralValue():
        * Generated Mutant 01: Replaced double division with multiplication 
            * Mutation Status: Killed
            * Analysis of the mutant: The expected operation for this method is division. And this mutant changes that operation to multiplication instead, clearly showing the stark difference between the two operations. 
            * Original test suite test case that likely killed this mutant: testCentralValueWithPositiveRange() and testCentralValueWithNegativeRange()
        * Generated Mutant 02: Substituted 2.0 with 1.0
            * Mutation Status: Killed
            * Analysis of the mutant: The expectation is the calculation of the average or the midpoint, and division by 2.0 is crucial for correctness and accuracy. But this mutant substitutes 2.0 with 1.0, thereby resulting in a calculation that doesn't halve the sum of the bounds, producing an incorrect result by not averaging the bounds.
            * Original test suite test case that likely killed this mutant: Even though all test cases are capable of killing this mutant since they all depend on the division by 2.0 for average calculation, there are two test cases: testCentralValueWithPositiveRange() and testCentralValueWithNegativeRange() that directly impacts the accuracy without the added complexities of extreme ranges or special conditions. 
    * Method 03: expand(Range range, double lowerMargin, double upperMargin):
        * Generated Mutant 01: Negated double local variable number 5 
            * Mutation Status: Survived
            * Analysis of the mutant: This mutant basically negates the fifth local variable. 
            * Original test suite test cases weren't able to kill this mutant. This may be due to the fact that there weren't any test cases that detected the calculation's intermediate step to pick up on the variable negation.
        * Generated Mutant 02: not equal to greater than
            * Mutation Status: Survived
            * Analysis of the mutant: This mutant basically replaces the comparison operator with a 'greater than' operator, thereby altering the logic of the conditional statements. 
            * Original test suite test cases weren't able to kill this mutant. This may be due to the fact that the test cases did not cover all the logical branches or edge cases that would be affected by this change. 
    * Method 04: scale(Range base, double factor):
        * Generated Mutant 01: negated conditional 
            * Mutation Status: Killed
            * Analysis of the mutant: This mutant negates the logic of the conditional statement, such as flipping the 'if' condition from true to false or vice versa. 
            * Original test suite test case that likely killed this mutant: testScaleByNegative() throws an exception when the scaling factor is negative and negating the condition results in failing the test, thereby killing the mutant.
        * Generated Mutant 02: Substituted 0.0 with 1.0
            * Mutation Status: Killed
            * Analysis of the mutant: This mutant alters the calculations that depend on a 0.0 value for the expected behaviour. 
            * Original test suite test case that likely killed this mutant: testScaleByZero() 
    * Method 05: equals(Object obj):
        * Generated Mutant 01: not equal to less or equal 
            * Mutation Status: Killed
            * Analysis of the mutant: This mutant changes the comparison operator to check for 'less than or equal to', basically inequality checks
            * Original test suite test case that likely killed this mutant: testDifferentLowerBound() and testDifferentUpperBound()
        * Generated Mutant 02: removed conditional - replaced equality check with false
            * Mutation Status: Killed
            * Analysis of the mutant: This mutant removes the conditional statement that checks for inequality, replacing any scenario where an equality condition would evaluate to true with a scenario where it always evaluates to false. 
            * Original test suite test case that likely killed this mutant: testSymmetry() tests that equality is symmetric, i.e., if 'range1.equals(range2)' is true, then 'range2.equals(range1)' should also be true. 

# Report all the statistics and the mutation score for each test class
- Range class:
    * Initial Run of Mutation test on Range class & its corresponding test suite:
      ![Overall_Initial_Range_Score](overall.png)
        * Statistics of Killed Mutants:
          
        ![Overall_Initial_Killed](overall_killed.png)
      
        * Statistics of Survived Mutants:
          
        ![Overall_Initial_Survived](overall_survived.png)
    * Final Run of Mutation test on Range class & its corresponding test suite with additional test cases:
    ![Overall_Final_Range_Score](overall_final.png)
        * Statistics of Killed Mutants:
          
        ![Overall_Final_Killed](overall_final_killed.png)

        * Statistics of Survived Mutants:
          
        ![Overall_Final_Survived](overall_final_survived.png)

# Analysis drawn on the effectiveness of each of the test classes
The mutation testing conducted on the Range class showed promising results, evident from the increase in the mutation score from 68% to 73%. This means that a significant portion of the mutants generated by the mutation testing tool were effectively identified and eliminated by the test suite. Moreover, the uptick in the mutation score suggests that the introduction of new test cases led to the detection and elimination of additional mutants. 
A key aspect of evaluating the effectiveness of mutation testing lies in scrutinizing the types of mutations introduced and their relevance in mimicking potential faults within the codebase. This scrutiny ensures that the identified mutants accurately reflect the real-world weaknesses in the code. 
The iterative nature of mutation testing allows for the identification and resolution of any deficiencies highlighted through the mutation analysis process, essentially needing continuous refinement of the test suite and the incorporation of new test cases. 

# A discussion on the effect of equivalent mutants on mutation score accuracy

# A discussion of what could have been done to improve the mutation score of the test suites
- Increasing the mutation score involves enhancing the accuracy of the test suite by introducing additional test cases to identify faults introduced by mutations. Here's a step-by-step approach or design plan for how we went about achieving this:
   * Assess initial mutation score: We first scrutinize the initial mutation score by running Pitest on the original test suite and the overall class. This evaluation reveals which parts of the code are well-covered and highlights areas requiring attention. In the case of the Range class, the initial mutation score was 68%. 
   * Spot low-coverage zones: We then identify segments within the codebase that lack adequate test coverage, contributing to the lower mutation score. We identify these as regions that require additional testing.
   * Prioritize Test case expansion: We focus on augmenting test cases in the low-coverage areas identified above. However, we observed that this strategy does not consistently yield the desired results. Specifically, upon examining the stats, we identified RangeTest16.java as having the lowest coverage at 32%. We opted to augment this particular test file with additional test cases. Despite our best efforts to enhance test coverage by adding more test cases to the method, the mutation coverage score decreased to 27%, basically introducing more mutants that remain unaddressed.
   * Identify mutation operators: Identify mutation operators that represent potential faults, and target them with new tests
   * Craft Test cases: Design new test cases tailored to cover the identified regions and target specific mutation operators.
   * Implement test cases: Write test code that simulates various scenarios and asserts the expected behavior of the code under test.
   * Run mutation testing: Perform JUnit testing to ensure there are no errors or failures. Re-run the mutation testing tool Pitest to evaluate the impact on the mutation score. Analyze the mutation report to ascertain whether the new tests have enhanced code coverage and fault detection capabilities.
   * Iterate and Refine: We then iterate on the test case design and implementation, adding further test cases as necessary to continuously improve the mutation score.
   * Monitor progress: Continuously monitor the mutation score and test coverage to identify areas for further enhancement. Then regularly update and refine the test suite to adapt to the changes in the codebase. 
# Why do we need mutation testing? Advantages and disadvantages of mutation testing

# Explain your SELENUIM test case design process

# Explain the use of assertions and checkpoints

# how did you test each functionaity with different test data

# How the team work/effort was divided and managed

# Difficulties encountered, challenges overcome, and lessons learned

# Comments/feedback on the assignment itself
