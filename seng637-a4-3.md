**SENG 637 - Dependability and Reliability of Software Systems**

**Lab. Report \#4 â€“ Mutation Testing and Web app testing**

| Group: 3      |
| -------------- |
| Aemen |
| Jauhar |
| Muhammad |
| Shaun |
| Soumini |

# Introduction

This lab aimed to enhance our grasp of mutation testing using JUnit and related frameworks. This included injecting mutation faults in the Java code for the DataRange and DataUtilities classes and their respective test cases. The tool used to acomplish this was Pitest, which is a plug-in for Eclipse. Using this tool, the SUT was infused with mutants to create a faulty version and the test suites were run to make sure they could accurately kill those mutants. The mutation score was then analyzed for each of the test suites to visualize their effects on the classes. New test cases were then created to try to minimize the mutants in the SUT and try to increase the overall mutation score of the DataRange and DataUtilities classes by 10%.

The second part of this assignment consisted of using GUI testing. The main focus for this part was on test automation, record and replay on the Home Depot website. The testing tool used for this part was the Selenium web-interfacing tool. This was used to create UI test cases, automate them and then verify and execute them to make sure there were no defects in the applications. To ensure optimal functionality, different data was also used to execute and test the functionality of a single test case.

# Analysis of 10 Mutants of the Range class 
- To examine 10 mutants generated by executing Pitest on the Range class, we consider five distinct methods within the Range class. Within each method, we select two mutants and analyze how they were killed or not by the original test suite.
    * Method 01: getLowerBound():
        * Generated Mutant 01: Negated double field lower 
            * Mutation Status: Killed
            * Analysis of the mutant: This mutant negates the value of the 'lower' field in the Range class. That is, if a positive lower bound value is expected, this mutant would return a negative value instead.
            * Original test suite test case that likely killed this mutant: getLowerBoundWithNegativeRange()
        * Generated Mutant 02: replaced double return with 0.0d for org/jfree/data/Range::getLowerBound
            * Mutation Status: Killed
            * Analysis of the mutant: This mutant indicates that the method will always return 0.0, irrespective of what the actual lower bound of the range is. 
            * Original test suite test case that likely killed this mutant: getLowerBoundWithNegativeRange() since it expects a distinctly non-zero, negative value, making it impossible for the mutant to pass this test. 
    * Method 02: getCentralValue():
        * Generated Mutant 01: Replaced double division with multiplication 
            * Mutation Status: Killed
            * Analysis of the mutant: The expected operation for this method is division. And this mutant changes that operation to multiplication instead, clearly showing the stark difference between the two operations. 
            * Original test suite test case that likely killed this mutant: testCentralValueWithPositiveRange() and testCentralValueWithNegativeRange()
        * Generated Mutant 02: Substituted 2.0 with 1.0
            * Mutation Status: Killed
            * Analysis of the mutant: The expectation is the calculation of the average or the midpoint, and division by 2.0 is crucial for correctness and accuracy. But this mutant substitutes 2.0 with 1.0, thereby resulting in a calculation that doesn't halve the sum of the bounds, producing an incorrect result by not averaging the bounds.
            * Original test suite test case that likely killed this mutant: Even though all test cases are capable of killing this mutant since they all depend on the division by 2.0 for average calculation, there are two test cases: testCentralValueWithPositiveRange() and testCentralValueWithNegativeRange() that directly impacts the accuracy without the added complexities of extreme ranges or special conditions. 
    * Method 03: expand(Range range, double lowerMargin, double upperMargin):
        * Generated Mutant 01: Negated double local variable number 5 
            * Mutation Status: Survived
            * Analysis of the mutant: This mutant basically negates the fifth local variable. 
            * Original test suite test cases weren't able to kill this mutant. This may be due to the fact that there weren't any test cases that detected the calculation's intermediate step to pick up on the variable negation.
        * Generated Mutant 02: not equal to greater than
            * Mutation Status: Survived
            * Analysis of the mutant: This mutant basically replaces the comparison operator with a 'greater than' operator, thereby altering the logic of the conditional statements. 
            * Original test suite test cases weren't able to kill this mutant. This may be due to the fact that the test cases did not cover all the logical branches or edge cases that would be affected by this change. 
    * Method 04: scale(Range base, double factor):
        * Generated Mutant 01: negated conditional 
            * Mutation Status: Killed
            * Analysis of the mutant: This mutant negates the logic of the conditional statement, such as flipping the 'if' condition from true to false or vice versa. 
            * Original test suite test case that likely killed this mutant: testScaleByNegative() throws an exception when the scaling factor is negative and negating the condition results in failing the test, thereby killing the mutant.
        * Generated Mutant 02: Substituted 0.0 with 1.0
            * Mutation Status: Killed
            * Analysis of the mutant: This mutant alters the calculations that depend on a 0.0 value for the expected behavior. 
            * Original test suite test case that likely killed this mutant: testScaleByZero() 
    * Method 05: equals(Object obj):
        * Generated Mutant 01: not equal to less or equal 
            * Mutation Status: Killed
            * Analysis of the mutant: This mutant changes the comparison operator to check for 'less than or equal to', basically inequality checks
            * Original test suite test case that likely killed this mutant: testDifferentLowerBound() and testDifferentUpperBound()
        * Generated Mutant 02: removed conditional - replaced equality check with false
            * Mutation Status: Killed
            * Analysis of the mutant: This mutant removes the conditional statement that checks for inequality, replacing any scenario where an equality condition would evaluate to true with a scenario where it always evaluates to false. 
            * Original test suite test case that likely killed this mutant: testSymmetry() tests that equality is symmetric, i.e., if 'range1.equals(range2)' is true, then 'range2.equals(range1)' should also be true. 

# Report all the statistics and the mutation score for each test class
- Range class:
    * Initial Run of Mutation test on Range class & its corresponding test suite:
      <img width="607" alt="overall" src="https://github.com/MuizMuhammad99/SENG637-A4/assets/126427676/0ffa7e1d-cc41-490e-891f-a1d8efb8f0ad">

      * Statistics of Killed Mutants:
      
      
          <img width="193" alt="overall_killed" src="https://github.com/MuizMuhammad99/SENG637-A4/assets/126427676/a1f21d66-7e78-4789-9ef0-8917d4ae5507">

      * Statistics of Survived Mutants:
        
          <img width="197" alt="overall_survived" src="https://github.com/MuizMuhammad99/SENG637-A4/assets/126427676/e7e41ded-a028-4b5c-a950-660819e49587">

      
    * Final Run of Mutation test on Range class & its corresponding test suite with additional test cases:
      <img width="610" alt="overall_final" src="https://github.com/MuizMuhammad99/SENG637-A4/assets/126427676/7684937f-4c0f-4700-9ce0-cbb0ebf47a13">

        * Statistics of Killed Mutants:
        <img width="196" alt="overall_final_killed" src="https://github.com/MuizMuhammad99/SENG637-A4/assets/126427676/259cbada-772a-46e5-bda6-215282efb9cd">

        * Statistics of Survived Mutants:
        <img width="200" alt="overall_final_survived" src="https://github.com/MuizMuhammad99/SENG637-A4/assets/126427676/7c43cd8f-40fc-4110-802a-386d2926c5ff">

- DataUtilities class:
    * Initial Run of Mutation test on DataUtilities class & its corresponding test suite:
      ![DU_Overall](https://github.com/MuizMuhammad99/SENG637-A4/assets/126427676/f1c5df47-edf6-4244-b23a-4cbd71a72c2d)


      * Statistics of Killed Mutants:
      
      
          ![DU_Initial_Killed](https://github.com/MuizMuhammad99/SENG637-A4/assets/126427676/f9d33afa-fa5e-40be-90aa-87e2c98d68b1)


      * Statistics of Survived Mutants:
        
          
         ![DU_Initial_Survived](https://github.com/MuizMuhammad99/SENG637-A4/assets/126427676/6315dadb-708a-40f1-9a3a-278868a748e5)

      
    * Final Run of Mutation test on DataUtilities class & its corresponding test suite with additional test cases:
      ![DU_Overall_Final](https://github.com/MuizMuhammad99/SENG637-A4/assets/126427676/c4e532e5-e4e1-496d-bacd-8c8df70c782d)


        * Statistics of Killed Mutants:
          
        ![DU_Final_Killed](https://github.com/MuizMuhammad99/SENG637-A4/assets/126427676/c933d63e-9ae4-4d84-8902-30fe009ef951)


        * Statistics of Survived Mutants:
          
        ![DU_Final_Survived](https://github.com/MuizMuhammad99/SENG637-A4/assets/126427676/15ae4198-98fe-4e10-a2a5-40ff3b1dfe86)


# Analysis drawn on the effectiveness of each of the test classes
## Range class: 

The mutation testing conducted on the Range class showed promising results, evident from the increase in the mutation score from 68% to 73%. This means that a significant portion of the mutants generated by the mutation testing tool were effectively identified and eliminated by the test suite. Moreover, the uptick in the mutation score suggests that the introduction of new test cases led to the detection and elimination of additional mutants. 

A key aspect of evaluating the effectiveness of mutation testing lies in scrutinizing the types of mutations introduced and their relevance in mimicking potential faults within the codebase. This scrutiny ensures that the identified mutants accurately reflect the real-world weaknesses in the code. 

The iterative nature of mutation testing allows for the identification and resolution of any deficiencies highlighted through the mutation analysis process, essentially needing continuous refinement of the test suite and the incorporation of new test cases.

## DataUtilities.java

All the 9 test classes developed rigorously test the methods in **DataUtilities.java** leveraging JMock for mock object creation and verifies the methodâ€™s behavior under diverse scenarios. Our testing process underwent several phases, starting with the identification and resolution of initial errors and failures in the test classes. After removing errors and failures in the test suite through continuous iterations the tests were made robust and dependable through rigorous Pit Test executions to achieve the most mutation coverage for each method. 

Remarkably, the test cases helped detect major redundancies in the source code and effectively helped increase the mutation coverage. We aimed to enhance the robustness of our test suite. This iterative approach allowed us to systematically identify and address potential vulnerabilities and edge cases and improve our test classes, thereby increasing the reliability and resilience of the methods in our source code.

For instance, let us consider both the **DataUtilitiesCalculateColumnTotal** and **DataUtilitiesCalculateColumnTotal2** test classes which handle different implementations of the `calculateColumnTotal` method. While one handles mutations specific to empty data sets and negative row counts, the other focuses on scenarios including empty values and various other data types. The use of mocked Values2D object is needed for both test classes to test the behavior of the method and error handling accurately against expectations.

Similar to that the **DataUtilitiesTest1** and **DataUtilitiesTest2** are used to test the `calculateRowTotal` method implementations, test cases like `calculateRowTotalForTwoValues` and `calculateRowTotalForSingleValue`, assess row totals for varying value counts, while others handle empty rows (`calculateRowTotalForEmptyRow`) or null input data (`calculateRowTotalForNullData`).

Next, the **DataUtilitiesCumulativePercentagesTest** class takes a systematic way to put into testing the `getCumulativePercentages` method within `DataUtilities`. Here the test cases are controlled using mocked KeyedValues objects which helps us check all the aspects of methods' functionality across different scenarios including varying numbers of values, different data types, and edge cases involving large, negative, and NaN values. 

The **DataUtilitiesClone**, **DataUtilitiesCreateNumberArray**, and **DataUtilitiesCreateNumberArray2D** test classes check the `clone`, `createNumberArray`, and `createNumberArray2D` methods respectively. Each test class checks for diverse cases such as handling null inputs and extreme values. Taking into account various real-life examples (calling upon null inputs and extreme values). By means of rigorous assertion evaluation and robust error handling the test classes ensure the methods are free from unexpected errors or failures.

The test cases were very effective and the mutation coverage achieved was ~90% (88%), which indicates that the methods tested the source code well for dependability and reliability. These test classes were crucial in identifying redundant code and improving mutation coverage.

# A discussion on the effect of equivalent mutants on mutation score accuracy
- In Part-1 of this Assignment we have created mutants (faulty versions) of the SUT, and then run the test suite against the mutants to determine if their test suite can accurately kill the introduced mutants.
- The number of mutants killed with respect to the number of introduced mutants gives us the mutation score percentage. A test suite with higher mutation score after introducing mutants and killing them is said to have higher ability to detect faults or mutants.
- Equivalent mutants have the same function (behavior) as the original code but its syntax differs. This type of mutants are very difficult to detect as the test cases run good on them and do not detect major errors as the expectation of the source code is fully satisfied.
- However, these mutants can be identified by analyzing the steps of the mutated code compared to the original code. If the mutated code produces the same outputs as the original code but includes additional statements with no functional purpose, uses different operators, or introduces unnecessary variables, it is more likely to contain equivalent mutants.
- Even after identifying these mutants the mutation testing score (quality) remains the same as they do not make any major change to the required output.
- If the test suite is not capable of detecting these equivalent mutants, it will have a bad effect when testing the code for real bugs. As a result the source code will be of low quality and less accuracy.
- In conclusion Equivalent mutants do not affect the final Mutation score accuracy but test suites which fail to detect these are said to be less reliable and have many unknown faults in results when actually tested.

# A discussion of what could have been done to improve the mutation score of the test suites
## Range class:
   Increasing the mutation score involves enhancing the accuracy of the test suite by introducing additional test cases to identify faults introduced by mutations. Here's a step-by-step approach or design plan for how we went about achieving this:
   * Assess initial mutation score: We first scrutinize the initial mutation score by running Pitest on the original test suite and the overall class. This evaluation reveals which parts of the code are well-covered and highlights areas requiring attention. In the case of the Range class, the initial mutation score was 68%. 
   * Spot low-coverage zones: We then identify segments within the codebase that lack adequate test coverage, contributing to the lower mutation score. We identify these as regions that require additional testing.
   * Prioritize Test case expansion: We focus on augmenting test cases in the low-coverage areas identified above.
     However, we observed that this strategy does not consistently yield the desired results. 
     <img width="604" alt="Screenshot 2024-03-28 044157" src="https://github.com/MuizMuhammad99/SENG637-A4/assets/126427676/c4d3b2cc-17e3-4d3e-a8ee-309b5593a034">

     Specifically, upon examining the stats, we identified RangeTest16.java as having the lowest coverage at 32%. We opted to augment this particular test file with additional test cases. Despite our best efforts to enhance test coverage by adding more test cases to the method, the mutation coverage score decreased to 27%, basically introducing more mutants that remain unaddressed.
     <img width="609" alt="Screenshot 2024-03-28 035436" src="https://github.com/MuizMuhammad99/SENG637-A4/assets/126427676/d37de1cb-0663-445e-bc35-c616ac332946">

   * Identify mutation operators: Identify mutation operators that represent potential faults, and target them with new tests
   * Craft Test cases: Design new test cases tailored to cover the identified regions and target specific mutation operators.
   * Implement test cases: Write test code that simulates various scenarios and asserts the expected behavior of the code under test.
   * Run mutation testing: Perform JUnit testing to ensure there are no errors or failures. Re-run the mutation testing tool Pitest to evaluate the impact on the mutation score. Analyze the mutation report to ascertain whether the new tests have enhanced code coverage and fault detection capabilities.
   * Iterate and Refine: We then iterate on the test case design and implementation, adding further test cases as necessary to continuously improve the mutation score.
   * Monitor progress: Continuously monitor the mutation score and test coverage to identify areas for further enhancement. Then regularly update and refine the test suite to adapt to the changes in the codebase. 

## DataUtilities.java

Siginificant improvements were made to the source code and the test suite was able to achieve a high mutation score. Overall, the test suites had to be improved to increase mutation score and the redundancies in the source code had to be fixed so the mutation score can be improved to ~88%. This can be further enhanced with more targeted test cases to improve it to 100%.

To make teÂ­sts better at finding bugs and ensuring codeÂ­ works, mutation scores could improve by employing the following methods:

- Firstly, we can add code paths to `DataUtilitieÂ­s` methods. This will cover more caseÂ­s.
- Second, we can analyse and look at survivors not caught. Find why and update tests for oveÂ­rlooked cases.

For instance, we can take the below conditional which was resulting in mutations that were due to the lack of branch coverage resulting from a wrong implementation of the conditional statement and we fixed it after checking the report for surviving mutations that kept persiting:

  <img width="490" alt="Coverage Error" src="https://github.com/MuizMuhammad99/SENG637-A4/assets/132412518/33ddda24-8f0b-4de3-bc8d-89ad740612e4">

After examinging the mutation coverage report we determined that it was the conditional statement that prevented the loop from eecuting for specific conditions that we were trying to test.

<img width="532" alt="Fixed" src="https://github.com/MuizMuhammad99/SENG637-A4/assets/132412518/d53888b2-afbe-4c81-ae5f-f256b64accdd">

This gave us better line coverage and we were able to test the method better.
  
- Thirdly, other tools (Jumble, Nester, and MuClipse) and libraries can be used to check what improvements to make so that we have an idea of what other mutations could arise in the code if tested on a different tool.
- Finally, diversifying teÂ­st inputs and further using different data typeÂ­s, boundary values, nulls, extremeÂ­s, and errors. 

This should test thoroughly for any remaining mutations. We can also make existing tests stronger by checking more parts of the code to find mistakes and look at different situations and details.


# Why do we need mutation testing? Advantages and disadvantages of mutation testing

Mutation testing is needed to check if our test suites can correctly detect all the mutants (faults) introduced in our code and ensures no real bug will be missed when performing actual testing. It is like trial and test method where the source code is testing all type of programming conditions where faults can occur.
# Advantages
- Helps identifying the less effective test cases which can be improved by the developers to increase the quality and coverage of the testing.
- Makes correction process (debugging) easier and less time consuming for the programmers.
- Tests if the score code works good and matches the expected output when any type of data is given.
- If the mutation testing score is high and overcomes all types of mutants then the score code is reliable or industry ready.
# Disadvantages
- It is time consuming as developers have to work on creating different test cases for different types of mutants that can occur in future instead of working with the actual project.
- Cannot identify and kill all the mutants. Some mutants will be live even after testing such as equivalent mutants.
- Writing test cases to kill the live bugs is a tedious process and it is still under development.

# Explain your SELENUIM test case design process

Since UI test cases are normally events that a user can execute on the website, the group decided to brainstorm any such events that might occur on the Home Depot webpage. A total of 10 test cases were needed for each student to automate 2 cases. Due to this, an overall of 12 test cases were designed if any cases did not work. These test cases included:

  * User Registration
  * User Valid Login 
  * User Invalid Login
  * User account management
  * Product Search
  * Product Comparison
  * Add to Cart
  * My Cart
  * Checkout Process
  * Wishlist
  * Credit Services
  * Store Locator

Out of all of these cases, the valid and invalid login were merged for effective testing of different data during the automation process. Moreover, the Credit Services were not tested. 

The designing of these test cases simply ocurred using the actual website. The SUT was created after the group browsed the different functionalities within the site. After browsing each page of the site, the main functions of that page were extracted. These functions were then fleshed out into the test case. Each test case included multiple ways to accomplish the main function of that page. After all possible methods were fully exhausted, the test case was complete and the group moved onto the next page or functionality within the website. The main method to ensure the test case was valid was to ensure all coverage criteria for the GUI testing was met. This criteria included ensuring all events of the website were executed, all states were exercised and all functionality and logical units were tested. 

# Explain the use of assertions and checkpoints

The automated assertions and verifications were used extensively in each script. Both assertions and verifications were used to ensure each test case created yielded the expected results. They assisted in detecting any irregularities or bugs in the website, if any. The assertions and verification checkpoints were added as described below:

  * User Registration: 
	- Verify Text: Account/Sign-in
	- Verify Text: Personal Account
	- Verify Text: An account already exists for this email
  * User Login (Valid/Invalid)
	- Verify Text: Please confirm the email address entered is correct
  * User account management
	- Verify Text: Account Dashboard
	- Verify Text: Order History
	- Verify Text: Buy Again
	- Verify Text: Shipping Addresses
	- Verify Text: Payment methods
  * Product Search
	- Assert Text: Pizza Oven Kit
	- Assert Text: Ora 12-inch Propane Gas Outdoor pizza Oven
	- Assert Text: Forno Venetzia
	- Assert Text: 16-inch Pizza Oven System
	- Assert Text: Bakerstone
	- Assert Text: Nexgrill
	- Assert Text: Electric
	- Assert Text: Fuel Type
	- Assert Text: Electric
	- Assert Text: Wood
	- Assert Text: Firewood, Wood
  * Product Comparison
	- Assert Text: Selected 2 of 4 items
	- Assert Text: Adler Single Handle Round Wall Mount
	- Assert Text: Compare More
	- Assert Text: Selected 3 of 4 items
	- Assert Text: Adler Single-Handle 4-spray Bathroom shower faucet
	- Assert Text: Genta Single-Handle 1-spray Bathroom shower faucet
  * Add to Cart
	- Assert Text: $358.00
	- Assert Text: 37
	- Assert Value: 1 
	- Assert Value: 8
	- Assert Text: 8 Item(s) in Cart
	- Assert Text: $358.00/each
	- Assert Text: $2864.00
  * My Cart
	- Assert Text: 1 Item(s) in Cart
	- Assert Text: 1 item(s)
	- Assert Text: $144.00/each
	- Assert Text: Order Subtotal
	- Assert Text: HDG
	- Assert Text: Hampton Bay
	- Assert Text: 2 Item(s) in Cart
	- Assert Text: $309.00
	- Assert Text: HDG 6 ft Laminate Countertop
	- Assert Text: Hampton Bay 74-Inch Laminate countertop
	- Assert Text: S165.00
	- Assert Text: Order Subtotal
	- Assert Text: My Cart: 1 item(s)
  * Checkout Process
	- Verify Text: Delivery
	- Verify Text: Payment
	- Verify Text: Please enter a valid card number
	- Verify Text: Review & Place Order
	- Verify Text: Estimated Order Total
  * Wishlist
	- Assert Text: Saved to the List
	- Assert Text: View List
	- Assert Text: My List
	- Assert Text: (1 item)
	- Assert Text: 24-inch Top Control Tall Tub
	- Assert Text: Monarch Specialties
	- Assert Text: Samsung 24-inch Top Controll Tall Tub Dishwasher
	- Assert Element Present
  * Store Locator
	- Verify Text: My Store
	- Verify Text: Store Services
	- Verify Text: Stores Nearby
	- Verify Text: Calgary North Hill
	- Verify Text: Store Services
	- Verify Text: Vehicle & Trailer Rental

Most of the assestions and verifications used were Assert and Verify Text to ensure each of the text and headings were able to be verified without any defects. Assert Value was used to ensure the proper value was added to the textboxes. Assert Element Present was used to ensure the mentioned element was properly called upon within the webpage.

# How did you test each functionaity with different test data

# How the team work/effort was divided and managed

The team was organized into three groups for collaborative coding efforts: 1) Aemen & Muiz, 2) Shaun & Fathima, and 3) Soumini. The division of work within the groups is as follows:
  * Shaun and Fathima worked on Mutation Testing for Data Utilities.
  * Soumini worked on Mutation Testing for Data Range class.
  * Muiz and Aemen worked on helping both Data Utilities and Data Range class wherever necessary.
  * Everyone did Selenium Testing

# Difficulties encountered, challenges overcome, and lessons learned
  * One of the main difficulties we had in this assignment was increasing the mutation score by 10%. Often at times we would introduce test cases that would introduce new mutants and increase the individual score of the test class themselves, however, this did not increase the mutation score of the DataUtilities.java or DataRange.java class themselves. In fact most of the times introducing new test cases resulted in the mutation score going down.

# Comments/feedback on the assignment itself
What we...

- **Liked:** We liked Selenium-ide as it was very straightforward and easy to use compared to the web-driver. 
- **Disliked:** We disliked how the Selenium-ide often made the web-page unresponsive when asserting data. This made it difficult to capture all the steps necessary and often required edits to the test-case itself.
- **Found Interesting:** It was interesting running Pitests and seeing the mutations being killed.
- **Found Confusing:** It was confusing how making changes to the test methods does not improve the mutation score of the overall class even though new mutants were introduced to the individual tests method.
- **Found Challenging:** The biggest challenge in this assignment was trying to raise the mutation score by 10%. Often at times it felt like we were shooting in the dark in hopes of increasing our score.
- **Found Motivating:** 
