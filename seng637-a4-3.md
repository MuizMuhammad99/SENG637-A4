**SENG 637 - Dependability and Reliability of Software Systems**

**Lab. Report \#4 – Mutation Testing and Web app testing**

| Group: 3      |
| -------------- |
| Aemen |
| Jauhar |
| Muhammad |
| Shaun |
| Soumini |

# Introduction

This lab aimed to enhance our grasp of mutation testing using JUnit and related frameworks. This included injecting mutation faults in the Java code for the DataRange and DataUtilities classes and their respective test cases. The tool used to acomplish this was Pitest, which is a plug-in for Eclipse. Using this tool, the SUT was infused with mutants to create a faulty version and the test suites were run to make sure they could accurately kill those mutants. The mutation score was then analyzed for each of the test suites to visualize their effects on the classes. New test cases were then created to try to minimize the mutants in the SUT and try to increase the overall mutation score of the DataRange and DataUtilities classes by 10%.

The second part of this assignment consisted of using GUI testing. The main focus for this part was on test automation, record and replay on the Home Depot website. The testing tool used for this part was the Selenium web-interfacing tool. This was used to create UI test cases, automate them and then verify and execute them to make sure there were no defects in the applications. To ensure optimal functionality, different data was also used to execute and test the functionality of a single test case.

# Analysis of 10 Mutants of the Range class 
- To examine 10 mutants generated by executing Pitest on the Range class, let us consider five distinct methods within the Range class. Within each method, we select two mutants and analyze how they were killed or not by the original test suite.
    * Method 01: getLowerBound():
        * Generated Mutant 01: Negated double field lower 
            * Mutation Status: Killed
            * Analysis of the mutant: This mutant negates the value of the 'lower' field in the Range class. That is, if a positive lower bound value is expected, this mutant would return a negative value instead.
            * Original test suite test case that likely killed this mutant: getLowerBoundWithNegativeRange()
        * Generated Mutant 02: replaced double return with 0.0d for org/jfree/data/Range::getLowerBound
            * Mutation Status: Killed
            * Analysis of the mutant: This mutant indicates that the method will always return 0.0, irrespective of what the actual lower bound of the range is. 
            * Original test suite test case that likely killed this mutant: getLowerBoundWithNegativeRange() since it expects a distinctly non-zero, negative value, making it impossible for the mutant to pass this test. 
    * Method 02: getCentralValue():
        * Generated Mutant 01: Replaced double division with multiplication 
            * Mutation Status: Killed
            * Analysis of the mutant: The expected operation for this method is division. And this mutant changes that operation to multiplication instead, clearly showing the stark difference between the two operations. 
            * Original test suite test case that likely killed this mutant: testCentralValueWithPositiveRange() and testCentralValueWithNegativeRange()
        * Generated Mutant 02: Substituted 2.0 with 1.0
            * Mutation Status: Killed
            * Analysis of the mutant: The expectation is the calculation of the average or the midpoint, and division by 2.0 is crucial for correctness and accuracy. But this mutant substitutes 2.0 with 1.0, thereby resulting in a calculation that doesn't halve the sum of the bounds, producing an incorrect result by not averaging the bounds.
            * Original test suite test case that likely killed this mutant: Even though all test cases are capable of killing this mutant since they all depend on the division by 2.0 for average calculation, there are two test cases: testCentralValueWithPositiveRange() and testCentralValueWithNegativeRange() that directly impacts the accuracy without the added complexities of extreme ranges or special conditions. 
    * Method 03: expand(Range range, double lowerMargin, double upperMargin):
        * Generated Mutant 01: Negated double local variable number 5 
            * Mutation Status: Survived
            * Analysis of the mutant: This mutant basically negates the fifth local variable. 
            * Original test suite test cases weren't able to kill this mutant. This may be due to the fact that there weren't any test cases that detected the calculation's intermediate step to pick up on the variable negation.
        * Generated Mutant 02: not equal to greater than
            * Mutation Status: Survived
            * Analysis of the mutant: This mutant basically replaces the comparison operator with a 'greater than' operator, thereby altering the logic of the conditional statements. 
            * Original test suite test cases weren't able to kill this mutant. This may be due to the fact that the test cases did not cover all the logical branches or edge cases that would be affected by this change. 
    * Method 04: scale(Range base, double factor):
        * Generated Mutant 01: negated conditional 
            * Mutation Status: Killed
            * Analysis of the mutant: This mutant negates the logic of the conditional statement, such as flipping the 'if' condition from true to false or vice versa. 
            * Original test suite test case that likely killed this mutant: testScaleByNegative() throws an exception when the scaling factor is negative and negating the condition results in failing the test, thereby killing the mutant.
        * Generated Mutant 02: Substituted 0.0 with 1.0
            * Mutation Status: Killed
            * Analysis of the mutant: This mutant alters the calculations that depend on a 0.0 value for the expected behaviour. 
            * Original test suite test case that likely killed this mutant: testScaleByZero() 
    * Method 05: equals(Object obj):
        * Generated Mutant 01: not equal to less or equal 
            * Mutation Status: Killed
            * Analysis of the mutant: This mutant changes the comparison operator to check for 'less than or equal to', basically inequality checks
            * Original test suite test case that likely killed this mutant: testDifferentLowerBound() and testDifferentUpperBound()
        * Generated Mutant 02: removed conditional - replaced equality check with false
            * Mutation Status: Killed
            * Analysis of the mutant: This mutant removes the conditional statement that checks for inequality, replacing any scenario where an equality condition would evaluate to true with a scenario where it always evaluates to false. 
            * Original test suite test case that likely killed this mutant: testSymmetry() tests that equality is symmetric, i.e., if 'range1.equals(range2)' is true, then 'range2.equals(range1)' should also be true. 

# Report all the statistics and the mutation score for each test class
- Range class:
    * Initial Run of Mutation test on Range class & its corresponding test suite:
      <img width="607" alt="overall" src="https://github.com/MuizMuhammad99/SENG637-A4/assets/126427676/0ffa7e1d-cc41-490e-891f-a1d8efb8f0ad">

      * Statistics of Killed Mutants:
      
      
          <img width="193" alt="overall_killed" src="https://github.com/MuizMuhammad99/SENG637-A4/assets/126427676/a1f21d66-7e78-4789-9ef0-8917d4ae5507">

      * Statistics of Survived Mutants:
        
          <img width="197" alt="overall_survived" src="https://github.com/MuizMuhammad99/SENG637-A4/assets/126427676/e7e41ded-a028-4b5c-a950-660819e49587">

      
    * Final Run of Mutation test on Range class & its corresponding test suite with additional test cases:
      <img width="610" alt="overall_final" src="https://github.com/MuizMuhammad99/SENG637-A4/assets/126427676/7684937f-4c0f-4700-9ce0-cbb0ebf47a13">

        * Statistics of Killed Mutants:
        <img width="196" alt="overall_final_killed" src="https://github.com/MuizMuhammad99/SENG637-A4/assets/126427676/259cbada-772a-46e5-bda6-215282efb9cd">

        * Statistics of Survived Mutants:
        <img width="200" alt="overall_final_survived" src="https://github.com/MuizMuhammad99/SENG637-A4/assets/126427676/7c43cd8f-40fc-4110-802a-386d2926c5ff">

- DataUtilities class:
    * Initial Run of Mutation test on DataUtilities class & its corresponding test suite:
      ![DU_Overall](https://github.com/MuizMuhammad99/SENG637-A4/assets/126427676/f1c5df47-edf6-4244-b23a-4cbd71a72c2d)


      * Statistics of Killed Mutants:
      
      
          ![DU_Initial_Killed](https://github.com/MuizMuhammad99/SENG637-A4/assets/126427676/f9d33afa-fa5e-40be-90aa-87e2c98d68b1)


      * Statistics of Survived Mutants:
        
          
         ![DU_Initial_Survived](https://github.com/MuizMuhammad99/SENG637-A4/assets/126427676/6315dadb-708a-40f1-9a3a-278868a748e5)

      
    * Final Run of Mutation test on DataUtilities class & its corresponding test suite with additional test cases:
      ![DU_Overall_Final](https://github.com/MuizMuhammad99/SENG637-A4/assets/126427676/c4e532e5-e4e1-496d-bacd-8c8df70c782d)


        * Statistics of Killed Mutants:
          
        ![DU_Final_Killed](https://github.com/MuizMuhammad99/SENG637-A4/assets/126427676/c933d63e-9ae4-4d84-8902-30fe009ef951)


        * Statistics of Survived Mutants:
          
        ![DU_Final_Survived](https://github.com/MuizMuhammad99/SENG637-A4/assets/126427676/15ae4198-98fe-4e10-a2a5-40ff3b1dfe86)


# Analysis drawn on the effectiveness of each of the test classes

## DataUtilities.java

All the 9 test classes developed rigorously test the methods in **DataUtilities.java** leveraging JMock for mock object creation and verifies the method’s behavior under diverse scenarios. Our testing process underwent several phases, starting with the identification and resolution of initial errors and failures in the test classes. After removing errors and failures in the test suite through continuous iterations the tests were made robust and dependable through rigorous Pit Test executions to achieve the most mutation coverage for each method. 

Remarkably, the test cases helped detect major redundancies in the source code and effectively helped increase the mutation coverage. We aimed to enhance the robustness of our test suite. This iterative approach allowed us to systematically identify and address potential vulnerabilities and edge cases and improve our test classes, thereby increasing the reliability and resilience of the methods in our source code.

For instance, let us consider both the **DataUtilitiesCalculateColumnTotal** and **DataUtilitiesCalculateColumnTotal2** test classes which handle different implementations of the `calculateColumnTotal` method. While one handles mutations specific to empty data sets and negative row counts, the other focuses on scenarios including empty values and various other data types. The use of mocked Values2D object is needed for both test classes to test the behavior of the method and error handling accurately against expectations.

Similar to that the **DataUtilitiesTest1** and **DataUtilitiesTest2** are used to test the `calculateRowTotal` method implementations, test cases like `calculateRowTotalForTwoValues` and `calculateRowTotalForSingleValue`, assess row totals for varying value counts, while others handle empty rows (`calculateRowTotalForEmptyRow`) or null input data (`calculateRowTotalForNullData`).

Next, the **DataUtilitiesCumulativePercentagesTest** class takes a systematic way to put into testing the `getCumulativePercentages` method within `DataUtilities`. Here the test cases are controlled using mocked KeyedValues objects which helps us check all the aspects of methods' functionality across different scenarios including varying numbers of values, different data types, and edge cases involving large, negative, and NaN values. 

The **DataUtilitiesClone**, **DataUtilitiesCreateNumberArray**, and **DataUtilitiesCreateNumberArray2D** test classes check the `clone`, `createNumberArray`, and `createNumberArray2D` methods respectively. Each test class checks for diverse cases such as handling null inputs and extreme values. Taking into account various real-life examples (calling upon null inputs and extreme values). By means of rigorous assertion evaluation and robust error handling the test classes ensure the methods are free from unexpected errors or failures.

The test cases were very effective and the mutation coverage achieved was ~90% (88%), which indicates that the methods tested the source code well for dependability and reliability. These test classes were crucial in identifying redundant code and improving mutation coverage.

# A discussion on the effect of equivalent mutants on mutation score accuracy

# A discussion of what could have been done to improve the mutation score of the test suites
## Range class:
   Increasing the mutation score involves enhancing the accuracy of the test suite by introducing additional test cases to identify faults introduced by mutations. Here's a step-by-step approach or design plan for how we went about achieving this:
   * Assess initial mutation score: We first scrutinize the initial mutation score by running Pitest on the original test suite and the overall class. This evaluation reveals which parts of the code are well-covered and highlights areas requiring attention. In the case of the Range class, the initial mutation score was 68%. 
   * Spot low-coverage zones: We then identify segments within the codebase that lack adequate test coverage, contributing to the lower mutation score. We identify these as regions that require additional testing.
   * Prioritize Test case expansion: We focus on augmenting test cases in the low-coverage areas identified above.
     However, we observed that this strategy does not consistently yield the desired results. 
     <img width="604" alt="Screenshot 2024-03-28 044157" src="https://github.com/MuizMuhammad99/SENG637-A4/assets/126427676/c4d3b2cc-17e3-4d3e-a8ee-309b5593a034">

     Specifically, upon examining the stats, we identified RangeTest16.java as having the lowest coverage at 32%. We opted to augment this particular test file with additional test cases. Despite our best efforts to enhance test coverage by adding more test cases to the method, the mutation coverage score decreased to 27%, basically introducing more mutants that remain unaddressed.
     <img width="609" alt="Screenshot 2024-03-28 035436" src="https://github.com/MuizMuhammad99/SENG637-A4/assets/126427676/d37de1cb-0663-445e-bc35-c616ac332946">

   * Identify mutation operators: Identify mutation operators that represent potential faults, and target them with new tests
   * Craft Test cases: Design new test cases tailored to cover the identified regions and target specific mutation operators.
   * Implement test cases: Write test code that simulates various scenarios and asserts the expected behavior of the code under test.
   * Run mutation testing: Perform JUnit testing to ensure there are no errors or failures. Re-run the mutation testing tool Pitest to evaluate the impact on the mutation score. Analyze the mutation report to ascertain whether the new tests have enhanced code coverage and fault detection capabilities.
   * Iterate and Refine: We then iterate on the test case design and implementation, adding further test cases as necessary to continuously improve the mutation score.
   * Monitor progress: Continuously monitor the mutation score and test coverage to identify areas for further enhancement. Then regularly update and refine the test suite to adapt to the changes in the codebase. 

## DataUtilities.java

Siginificant improvements were made to the source code and the test suite was able to achieve a high mutation score. Overall, the test suites had to be improved to increase mutation score and the redundancies in the source code had to be fixed so the mutation score can be improved to ~88%. This can be further enhanced with more targeted test cases to improve it to 100%.

To make te­sts better at finding bugs and ensuring code­ works, mutation scores could improve by employing the following methods:

- Firstly, we can add code paths to `DataUtilitie­s` methods. This will cover more case­s.
- Second, we can analyse and look at survivors not caught. Find why and update tests for ove­rlooked cases. 
- Thirdly, other tools (Jumble, Nester, and MuClipse) and libraries can be used to check what improvements to make so that we have an idea of what other mutations could arise in the code if tested on a different tool.
- Finally, diversifying te­st inputs and further using different data type­s, boundary values, nulls, extreme­s, and errors. 

This should test thoroughly for any remaining mutations. We can also make existing tests stronger by checking more parts of the code to find mistakes and look at different situations and details.


# Why do we need mutation testing? Advantages and disadvantages of mutation testing

# Explain your SELENUIM test case design process

Since UI test cases are normally events that a user can execute on the website, the group decided to brainstorm any such events that might occur on the Home Depot webpage. A total of 10 test cases were needed for each student to automate 2 cases. Due to this, an overall of 12 test cases were designed if any cases did not work. These test cases included:

  * User Registration
  * User Valid Login 
  * User Invalid Login
  * User account management
  * Product Search
  * Product Comparison
  * Add to Cart
  * My Cart
  * Checkout Process
  * Wishlist
  * Credit Services
  * Store Locator

Out of all of these cases, the valid and invalid login were merged for effective testing of different data during the automation process. Moreover, the Credit Services were not tested. 

The designing of these test cases simply ocurred using the actual website. The SUT was created after the group browsed the different functionalities within the site. After browsing each page of the site, the main functions of that page were extracted. These functions were then fleshed out into the test case. Each test case included multiple ways to accomplish the main function of that page. After all possible methods were fully exhausted, the test case was complete and the group moved onto the next page or functionality within the website. The main method to ensure the test case was valid was to ensure all coverage criteria for the GUI testing was met. This criteria included ensuring all events of the website were executed, all states were exercised and all functionality and logical units were tested. 

# Explain the use of assertions and checkpoints

# how did you test each functionaity with different test data

# How the team work/effort was divided and managed

The team was organized into three groups for collaborative coding efforts: 1) Aemen & Muiz, 2) Shaun & Fathima, and 3) Soumini. The division of work within the groups is as follows:
  * Shaun and Fathima worked on Mutation Testing for Data Utilities.
  * Soumini worked on Mutation Testing for Data Range class.
  * Muiz and Aemen worked on helping both Data Utilities and Data Range class wherever necessary.
  * Everyone did Selenium Testing

# Difficulties encountered, challenges overcome, and lessons learned
  * One of the main difficulties we had in this assignment was increasing the mutation score by 10%. Often at times we would introduce test cases that would introduce new mutants and increase the individual score of the test class themselves, however, this did not increase the mutation score of the DataUtilities.java or DataRange.java class themselves. In fact most of the times introducing new test cases resulted in the mutation score going down.

# Comments/feedback on the assignment itself
What we...

- **Liked:** We liked Selenium-ide as it was very straightforward and easy to use compared to the web-driver. 
- **Disliked:** We disliked how the Selenium-ide often made the web-page unresponsive when asserting data. This made it difficult to capture all the steps necessary and often required edits to the test-case itself.
- **Found Interesting:** It was interesting running Pitests and seeing the mutations being killed.
- **Found Confusing:** It was confusing how making changes to the test methods does not improve the mutation score of the overall class even though new mutants were introduced to the individual tests method.
- **Found Challenging:** The biggest challenge in this assignment was trying to raise the mutation score by 10%. Often at times it felt like we were shooting in the dark in hopes of increasing our score.
- **Found Motivating:** 
