**SENG 637 - Dependability and Reliability of Software Systems**

**Lab. Report \#4 – Mutation Testing and Web app testing**

| Group: 3      |
| -------------- |
| Aemen |
| Muhammad |
| Shaun |
| Soumini |

# Introduction

This lab aimed to enhance our grasp of mutation testing using JUnit and related frameworks. This included injecting mutation faults in the Java code for the DataRange and DataUtilities classes and their respective test cases. The tool used to acomplish this was Pitest, which is a plug-in for Eclipse. Using this tool, the SUT was infused with mutants to create a faulty version and the test suites were run to make sure they could accurately kill those mutants. The mutation score was then analyzed for each of the test suites to visualize their effects on the classes. New test cases were then created to try to minimize the mutants in the SUT and try to increase the overall mutation score of the DataRange and DataUtilities classes by 10%.

The second part of this assignment consisted of using GUI testing. The main focus for this part was on test automation, record and replay. The testing tool used for this part was the Selenium web-interfacing tool. This was used to create UI test cases, automate them and then verify and execute them to make sure there were no defects in the applications. To ensure optimal functionality, different data was also used to execute and test the functionality of a single test case.

# Analysis of 10 Mutants of the Range class 

# Report all the statistics and the mutation score for each test class

# Analysis drawn on the effectiveness of each of the test classes

## DataUtilities.java

All the 9 test classes developed rigorously test the methods in **DataUtilities.java** leveraging JMock for mock object creation and verifies the method’s behavior under diverse scenarios. Our testing process underwent several phases, starting with the identification and resolution of initial errors and failures in the test classes. After removing errors and failures in the test suite through continuous iterations the tests were made robust and dependable through rigorous Pit Test executions to achieve the most mutation coverage for each method. 

Remarkably, the test cases helped detect major redundancies in the source code and effectively helped increase the mutation coverage. We aimed to enhance the robustness of our test suite. This iterative approach allowed us to systematically identify and address potential vulnerabilities and edge cases and improve our test classes, thereby increasing the reliability and resilience of the methods in our source code.

For instance, let us consider both the **DataUtilitiesCalculateColumnTotal** and **DataUtilitiesCalculateColumnTotal2** test classes which handle different implementations of the `calculateColumnTotal` method. While one handles mutations specific to empty data sets and negative row counts, the other focuses on scenarios including empty values and various other data types. The use of mocked Values2D object is needed for both test classes to test the behavior of the method and error handling accurately against expectations.

Similar to that the **DataUtilitiesTest1** and **DataUtilitiesTest2** are used to test the `calculateRowTotal` method implementations, test cases like `calculateRowTotalForTwoValues` and `calculateRowTotalForSingleValue`, assess row totals for varying value counts, while others handle empty rows (`calculateRowTotalForEmptyRow`) or null input data (`calculateRowTotalForNullData`).

Next, the **DataUtilitiesCumulativePercentagesTest** class takes a systematic way to put into testing the `getCumulativePercentages` method within `DataUtilities`. Here the test cases are controlled using mocked KeyedValues objects which helps us check all the aspects of methods' functionality across different scenarios including varying numbers of values, different data types, and edge cases involving large, negative, and NaN values. 

The **DataUtilitiesClone**, **DataUtilitiesCreateNumberArray**, and **DataUtilitiesCreateNumberArray2D** test classes check the `clone`, `createNumberArray`, and `createNumberArray2D` methods respectively. Each test class checks for diverse cases such as handling null inputs and extreme values. Taking into account various real-life examples (calling upon null inputs and extreme values). By means of rigorous assertion evaluation and robust error handling the test classes ensure the methods are free from unexpected errors or failures.

The test cases were very effective and the mutation coverage achieved was ~90% (88%), which indicates that the methods tested the source code well for dependability and reliability. These test classes were crucial in identifying redundant code and improving mutation coverage.

# A discussion on the effect of equivalent mutants on mutation score accuracy

# A discussion of what could have been done to improve the mutation score of the test suites

# Why do we need mutation testing? Advantages and disadvantages of mutation testing

# Explain your SELENUIM test case design process

# Explain the use of assertions and checkpoints

# how did you test each functionaity with different test data

# How the team work/effort was divided and managed

The team was organized into three groups for collaborative coding efforts: 1) Aemen & Muiz, 2) Shaun, and 3) Soumini. The division of work within the groups is as follows:
  * Shaun worked on Mutation Testing for Data Utilities.
  * Soumini worked on Mutation Testing for Data Range class.
  * Muiz and Aemen worked on helping both Data Utilities and Data Range class wherever necessary.
  * Everyone did Selenium Testing

# Difficulties encountered, challenges overcome, and lessons learned
  * One of the main difficulties we had in this assignment was increasing the mutation score by 10%. Often at times we would introduce test cases that would introduce new mutants and increase the individual score of the test class themselves, however, this did not increase the mutation score of the DataUtilities.java or DataRange.java class themselves. In fact most of the times introducing new test cases resulted in the mutation score going down.

# Comments/feedback on the assignment itself
What we...

- **Liked:** We liked Selenium-ide as it was very straightforward and easy to use compared to the web-driver. 
- **Disliked:** We disliked how the Selenium-ide often made the web-page unresponsive when asserting data. This made it difficult to capture all the steps necessary and often required edits to the test-case itself.
- **Found Interesting:** It was interesting running Pitests and seeing the mutations being killed.
- **Found Confusing:** It was confusing how making changes to the test methods does not improve the mutation score of the overall class even though new mutants were introduced to the individual tests method.
- **Found Challenging:** The biggest challenge in this assignment was trying to raise the mutation score by 10%. Often at times it felt like we were shooting in the dark in hopes of increasing our score.
- **Found Motivating:** 
